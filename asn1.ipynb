{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SDA 250 - Assignment 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Group 9:<br>\n",
    "Cindy Lee<br>\n",
    "Woochul Song<br>\n",
    "Ralph Guillermo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Load packages and data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import string\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import FreqDist\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = './data/'\n",
    "data = PlaintextCorpusReader(corpus_root, '.*')"
   ]
  },
  {
   "source": [
    "## 2. Defining functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. length (in words)\n",
    "def print_length(words):\n",
    "    print(\"length:\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. lexical diversity\n",
    "def lexical_diversity(words):\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "def print_lexical_diversity(words):\n",
    "    print(\"lexical diversity:\", lexical_diversity(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. print longest sentence in the file\n",
    "def print_longest_sentence(sentence):\n",
    "    longest_len = max(len(s) for s in sentence)\n",
    "    print(\"longest sentence:\", [s for s in sentence if len(s) == longest_len])\n",
    "    print(\"longest sentence length:\", longest_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. collocations\n",
    "def print_collocations(text):    \n",
    "    stops = stopwords.words('english')\n",
    "    words = [word for word in text if word not in stops]\n",
    "    #punctuations = list(string.punctuation)\n",
    "    #words = [word for word in words if word not in punctuations]\n",
    "    words = [word for word in words if any(c.isalpha() for c in word)]\n",
    "    \n",
    "    bigram_collocation = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "    print(\"Top 10 Collocations:\", bigram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. the top ten words that start with each of the vowels\n",
    "def print_ten_words_start_with_vowels(words):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    for v in vowels:\n",
    "        vowel_words = [t for t in words if t.startswith(v)]\n",
    "        fdist_vowel = FreqDist(vowel_words)\n",
    "        print(\"Top 10 words that start with\", v, \":\\n\", fdist_vowel.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. A stemmed version of the longest sentence\n",
    "def print_stemmed_longest_sentence(sentences): # Define function\n",
    "    ps = PorterStemmer() # Rename fx for easier use\n",
    "    maxsentlen = max(len(s) for s in sentences) # Find the longest sentence\n",
    "    maxsent = (s for s in sentences if len(s) == maxsentlen) # Put the list of words from the longest sentence in a list\n",
    "    var = 0 # Create empty variable for loop\n",
    "    stemmed = []\n",
    "    for i in maxsent: # Nested for loop to iterate over the words inside the list\n",
    "        #print(\"Word\", \":\", \"Stemmed Word\", \"\\n\") # Make column names for readability\n",
    "        for j in range (0, maxsentlen):  # Second for-loop to define how many times to continue the loop\n",
    "            #p = i[var] # P storage for the word that is currently being iterated over\n",
    "            #print(p, \":\", ps.stem(p)) # Print the word and the stemmed version\n",
    "            stemmed.append(ps.stem(i[j]))\n",
    "    print(\"Stemmed longest sentence: \", stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats of a file\n",
    "def print_answers(filename, words, sentences):\n",
    "    print(filename, \":\")\n",
    "    print_length(words)\n",
    "    print_lexical_diversity(words)\n",
    "    print_longest_sentence(sentences)\n",
    "    print_collocations(words)\n",
    "    print_ten_words_start_with_vowels(words)\n",
    "    print_stemmed_longest_sentence(sentences)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "source": [
    "## 3. Answers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "grimms.txt :\n",
      "length: 124554\n",
      "lexical diversity: 0.04713618189700853\n",
      "longest sentence: [['When', 'he', 'found', 'himself', 'safe', ',', 'he', 'was', 'overjoyed', 'to', 'think', 'that', 'he', 'had', 'got', 'the', 'Water', 'of', 'Life', ';', 'and', 'as', 'he', 'was', 'going', 'on', 'his', 'way', 'homewards', ',', 'he', 'passed', 'by', 'the', 'little', 'dwarf', ',', 'who', ',', 'when', 'he', 'saw', 'the', 'sword', 'and', 'the', 'loaf', ',', 'said', ',', '‘', 'You', 'have', 'made', 'a', 'noble', 'prize', ';', 'with', 'the', 'sword', 'you', 'can', 'at', 'a', 'blow', 'slay', 'whole', 'armies', ',', 'and', 'the', 'bread', 'will', 'never', 'fail', 'you', '.’', 'Then', 'the', 'prince', 'thought', 'to', 'himself', ',', '‘', 'I', 'cannot', 'go', 'home', 'to', 'my', 'father', 'without', 'my', 'brothers', '’;', 'so', 'he', 'said', ',', '‘', 'My', 'dear', 'friend', ',', 'cannot', 'you', 'tell', 'me', 'where', 'my', 'two', 'brothers', 'are', ',', 'who', 'set', 'out', 'in', 'search', 'of', 'the', 'Water', 'of', 'Life', 'before', 'me', ',', 'and', 'never', 'came', 'back', '?’', '‘', 'I', 'have', 'shut', 'them', 'up', 'by', 'a', 'charm', 'between', 'two', 'mountains', ',’', 'said', 'the', 'dwarf', ',', '‘', 'because', 'they', 'were', 'proud', 'and', 'ill', '-', 'behaved', ',', 'and', 'scorned', 'to', 'ask', 'advice', '.’', 'The', 'prince', 'begged', 'so', 'hard', 'for', 'his', 'brothers', ',', 'that', 'the', 'dwarf', 'at', 'last', 'set', 'them', 'free', ',', 'though', 'unwillingly', ',', 'saying', ',', '‘', 'Beware', 'of', 'them', ',', 'for', 'they', 'have', 'bad', 'hearts', '.’', 'Their', 'brother', ',', 'however', ',', 'was', 'greatly', 'rejoiced', 'to', 'see', 'them', ',', 'and', 'told', 'them', 'all', 'that', 'had', 'happened', 'to', 'him', ';', 'how', 'he', 'had', 'found', 'the', 'Water', 'of', 'Life', ',', 'and', 'had', 'taken', 'a', 'cup', 'full', 'of', 'it', ';', 'and', 'how', 'he', 'had', 'set', 'a', 'beautiful', 'princess', 'free', 'from', 'a', 'spell', 'that', 'bound', 'her', ';', 'and', 'how', 'she', 'had', 'engaged', 'to', 'wait', 'a', 'whole', 'year', ',', 'and', 'then', 'to', 'marry', 'him', ',', 'and', 'to', 'give', 'him', 'the', 'kingdom', '.']]\n",
      "longest sentence length: 281\n",
      "Top 10 Collocations: [('Project', 'Gutenberg'), ('Gutenberg', 'tm'), ('old', 'woman'), ('Red', 'Cap'), ('At', 'last'), ('Literary', 'Archive'), ('Water', 'Life'), ('Snow', 'white'), ('tm', 'electronic'), ('little', 'tailor')]\n",
      "Top 10 words that start with a :\n",
      " [('and', 5300), ('a', 1942), ('as', 721), ('all', 584), ('at', 551), ('away', 288), ('again', 279), ('are', 231), ('about', 176), ('am', 150)]\n",
      "Top 10 words that start with e :\n",
      " [('eat', 92), ('each', 76), ('every', 69), ('evening', 68), ('eyes', 63), ('enough', 51), ('end', 39), ('everything', 38), ('eldest', 32), ('even', 32)]\n",
      "Top 10 words that start with i :\n",
      " [('it', 1251), ('in', 1158), ('into', 480), ('is', 478), ('if', 255), ('its', 51), ('ill', 26), ('indeed', 20), ('inside', 16), ('iron', 14)]\n",
      "Top 10 words that start with o :\n",
      " [('of', 1461), ('on', 620), ('out', 470), ('one', 377), ('old', 201), ('or', 197), ('off', 195), ('over', 147), ('other', 143), ('once', 132)]\n",
      "Top 10 words that start with u :\n",
      " [('up', 404), ('upon', 198), ('us', 79), ('under', 71), ('until', 60), ('use', 34), ('upstairs', 15), ('used', 14), ('unless', 12), ('uneasy', 11)]\n",
      "Stemmed longest sentence:  ['when', 'he', 'found', 'himself', 'safe', ',', 'he', 'wa', 'overjoy', 'to', 'think', 'that', 'he', 'had', 'got', 'the', 'water', 'of', 'life', ';', 'and', 'as', 'he', 'wa', 'go', 'on', 'hi', 'way', 'homeward', ',', 'he', 'pass', 'by', 'the', 'littl', 'dwarf', ',', 'who', ',', 'when', 'he', 'saw', 'the', 'sword', 'and', 'the', 'loaf', ',', 'said', ',', '‘', 'you', 'have', 'made', 'a', 'nobl', 'prize', ';', 'with', 'the', 'sword', 'you', 'can', 'at', 'a', 'blow', 'slay', 'whole', 'armi', ',', 'and', 'the', 'bread', 'will', 'never', 'fail', 'you', '.’', 'then', 'the', 'princ', 'thought', 'to', 'himself', ',', '‘', 'I', 'cannot', 'go', 'home', 'to', 'my', 'father', 'without', 'my', 'brother', '’;', 'so', 'he', 'said', ',', '‘', 'My', 'dear', 'friend', ',', 'cannot', 'you', 'tell', 'me', 'where', 'my', 'two', 'brother', 'are', ',', 'who', 'set', 'out', 'in', 'search', 'of', 'the', 'water', 'of', 'life', 'befor', 'me', ',', 'and', 'never', 'came', 'back', '?’', '‘', 'I', 'have', 'shut', 'them', 'up', 'by', 'a', 'charm', 'between', 'two', 'mountain', ',’', 'said', 'the', 'dwarf', ',', '‘', 'becaus', 'they', 'were', 'proud', 'and', 'ill', '-', 'behav', ',', 'and', 'scorn', 'to', 'ask', 'advic', '.’', 'the', 'princ', 'beg', 'so', 'hard', 'for', 'hi', 'brother', ',', 'that', 'the', 'dwarf', 'at', 'last', 'set', 'them', 'free', ',', 'though', 'unwillingli', ',', 'say', ',', '‘', 'bewar', 'of', 'them', ',', 'for', 'they', 'have', 'bad', 'heart', '.’', 'their', 'brother', ',', 'howev', ',', 'wa', 'greatli', 'rejoic', 'to', 'see', 'them', ',', 'and', 'told', 'them', 'all', 'that', 'had', 'happen', 'to', 'him', ';', 'how', 'he', 'had', 'found', 'the', 'water', 'of', 'life', ',', 'and', 'had', 'taken', 'a', 'cup', 'full', 'of', 'it', ';', 'and', 'how', 'he', 'had', 'set', 'a', 'beauti', 'princess', 'free', 'from', 'a', 'spell', 'that', 'bound', 'her', ';', 'and', 'how', 'she', 'had', 'engag', 'to', 'wait', 'a', 'whole', 'year', ',', 'and', 'then', 'to', 'marri', 'him', ',', 'and', 'to', 'give', 'him', 'the', 'kingdom', '.']\n",
      "\n",
      "\n",
      "putin.txt :\n",
      "length: 7768\n",
      "lexical diversity: 0.22657054582904224\n",
      "longest sentence: [['There', 'is', 'some', 'discussion', 'here', 'about', 'how', 'popular', 'the', 'Kremlin', \"'\", 's', 'uncompromising', 'stance', 'might', 'be', 'amongst', 'senior', 'officials', ',', 'as', 'Western', 'governments', 'consider', 'new', 'sanctions', ':', 'asset', 'freezes', 'and', 'travel', 'bans', 'are', 'an', 'acceptable', 'price', 'for', 'a', 'patriotic', 'project', 'like', '\"', 'returning', '\"', 'Crimea', ',', 'but', 'targeting', 'an', 'opposition', 'politician', 'may', 'be', 'a', 'less', 'popular', 'cause', '.']]\n",
      "longest sentence length: 58\n",
      "Top 10 Collocations: [('bbc', 'com'), ('https', 'www'), ('world', 'europe'), ('www', 'bbc'), ('com', 'news'), ('Mr', 'Navalny'), ('Alexei', 'Navalny'), ('nerve', 'agent'), ('President', 'Vladimir'), ('news', 'world')]\n",
      "Top 10 words that start with a :\n",
      " [('a', 152), ('and', 127), ('as', 56), ('an', 23), ('are', 22), ('at', 19), ('agent', 17), ('after', 16), ('attack', 15), ('against', 15)]\n",
      "Top 10 words that start with e :\n",
      " [('europe', 13), ('embezzlement', 6), ('experts', 5), ('expulsion', 4), ('emergency', 4), ('earlier', 4), ('expulsions', 3), ('economic', 3), ('elections', 3), ('even', 3)]\n",
      "Top 10 words that start with i :\n",
      " [('in', 157), ('is', 45), ('it', 23), ('into', 9), ('if', 8), ('involvement', 7), ('including', 7), ('investigation', 6), ('its', 5), ('immediate', 4)]\n",
      "Top 10 words that start with o :\n",
      " [('of', 133), ('on', 69), ('opposition', 16), ('out', 12), ('over', 9), ('our', 8), ('one', 8), ('or', 8), ('only', 7), ('officials', 6)]\n",
      "Top 10 words that start with u :\n",
      " [('up', 10), ('under', 10), ('used', 6), ('unauthorised', 4), ('urged', 2), ('using', 2), ('unlikely', 2), ('us', 2), ('unjustified', 1), ('unanswered', 1)]\n",
      "Stemmed longest sentence:  ['there', 'is', 'some', 'discuss', 'here', 'about', 'how', 'popular', 'the', 'kremlin', \"'\", 's', 'uncompromis', 'stanc', 'might', 'be', 'amongst', 'senior', 'offici', ',', 'as', 'western', 'govern', 'consid', 'new', 'sanction', ':', 'asset', 'freez', 'and', 'travel', 'ban', 'are', 'an', 'accept', 'price', 'for', 'a', 'patriot', 'project', 'like', '\"', 'return', '\"', 'crimea', ',', 'but', 'target', 'an', 'opposit', 'politician', 'may', 'be', 'a', 'less', 'popular', 'caus', '.']\n",
      "\n",
      "\n",
      "tweets.txt :\n",
      "length: 20244\n",
      "lexical diversity: 0.22248567476783243\n",
      "longest sentence: [['Julia', 'Would', 'Like', 'To', 'Fill', 'The', 'Seat', 'Of', 'Her', 'Husband', 'Luke', ',', 'Who', 'Passed', 'Away', 'From', 'COVID', '-', '19', 'Sadly', ',', 'Before', 'Being', 'Sworn', 'In', '<', 'U', '+', '0001F339', '>', 'Julie', '’', 's', 'Motivation', 'Is', 'The', 'Passion', 'Her', 'And', 'Luke', 'Shared', 'To', 'Better', 'The', 'Region', 'For', 'Their', 'Children', 'And', 'Future', 'Generations', '<', 'U', '+', '0001F339', '>#', 'VoteRed', '<', 'U', '+', '0001F339', '>#', 'GoRedStateByState', '<', 'U', '+', '0001F339', '>#', 'VoteRepublican', 'https', '://', 't', '.', 'co', '/', 'nEALNGsJEu', '.']]\n",
      "longest sentence length: 77\n",
      "Top 10 Collocations: [('https', 'co'), ('Assessing', 'Fallout'), ('Fallout', 'From'), ('By', 'IndexMarketsResearch'), ('Market', 'Assessing'), ('Pandemic', 'By'), ('worldwide', 'That'), ('Since', 'start'), ('York', 'Times'), ('From', 'COVID')]\n",
      "Top 10 words that start with a :\n",
      " [('and', 176), ('a', 143), ('as', 78), ('are', 45), ('at', 39), ('all', 31), ('about', 31), ('amp', 27), ('after', 24), ('an', 19)]\n",
      "Top 10 words that start with e :\n",
      " [('economy', 10), ('even', 7), ('end', 6), ('enough', 6), ('economic', 5), ('enter', 4), ('exposed', 4), ('events', 4), ('ever', 3), ('early', 3)]\n",
      "Top 10 words that start with i :\n",
      " [('in', 200), ('is', 81), ('it', 50), ('if', 15), ('its', 14), ('into', 10), ('information', 9), ('including', 6), ('isolate', 4), ('impact', 4)]\n",
      "Top 10 words that start with o :\n",
      " [('of', 268), ('on', 100), ('our', 26), ('out', 24), ('or', 16), ('over', 15), ('one', 15), ('open', 11), ('other', 11), ('only', 8)]\n",
      "Top 10 words that start with u :\n",
      " [('up', 15), ('us', 10), ('unfit', 7), ('under', 6), ('use', 5), ('using', 5), ('used', 4), ('update', 3), ('updates', 3), ('until', 3)]\n",
      "Stemmed longest sentence:  ['julia', 'would', 'like', 'To', 'fill', 'the', 'seat', 'Of', 'her', 'husband', 'luke', ',', 'who', 'pass', 'away', 'from', 'covid', '-', '19', 'sadli', ',', 'befor', 'be', 'sworn', 'In', '<', 'U', '+', '0001f339', '>', 'juli', '’', 's', 'motiv', 'Is', 'the', 'passion', 'her', 'and', 'luke', 'share', 'To', 'better', 'the', 'region', 'for', 'their', 'children', 'and', 'futur', 'gener', '<', 'U', '+', '0001f339', '>#', 'voter', '<', 'U', '+', '0001f339', '>#', 'goredstatebyst', '<', 'U', '+', '0001f339', '>#', 'voterepublican', 'http', '://', 't', '.', 'co', '/', 'nealngsjeu', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main part: print all the answers\n",
    "filenames = ['grimms.txt', 'putin.txt', 'tweets.txt']\n",
    "for f in filenames:\n",
    "    w = data.words(f)\n",
    "    s = data.sents(f)\n",
    "    print_answers(f, w, s)"
   ]
  }
 ]
}